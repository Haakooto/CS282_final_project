{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer as lbc\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from models import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import training_utils as utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 30])\n",
      "torch.Size([569])\n"
     ]
    }
   ],
   "source": [
    "X, y = lbc(return_X_y=True)\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n",
    "data = utils.CustomDataObject(X, y)\n",
    "data = torch.utils.data.DataLoader(data, batch_size=1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical(y):\n",
    "    N = len(y)\n",
    "    M = np.max(y) + 1\n",
    "    Y = np.zeros((N, M))\n",
    "    for i in range(N):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, optimizer, train_loader, device, num_epochs=30):\n",
    "    # pbar = tqdm(range(num_epochs))\n",
    "    for i in range(num_epochs):\n",
    "        for bi, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out, kl = model(x)\n",
    "            print(out)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            print(out)\n",
    "            \n",
    "            \n",
    "            loss = F.nll_loss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: i, loss: {loss}\")\n",
    "        exit()\n",
    "        # pbar.set_description(f\"{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianFC(X.shape[1], 2, [20, 20])\n",
    "optim = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.5961e-53]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6542e-77, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 8.5789e-311]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.7662e-109,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.0397e-138,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 8.5207e-309]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4950e-251,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.2678e-170,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8956e-29]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.2716e-51]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 5.4835e-299]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 9.2721e-16]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.5758e-159]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8299e-41]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.8960e-248,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.8308e-210]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 5.5112e-65]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4188e-262,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.3923e-105]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.1797e-289]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9964e-274,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.9397e-159]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3909e-272,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.0655e-197,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 7.4736e-233]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5839e-129,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6365e-316,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0660e-294,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.6011e-182]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 7.7305e-66]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.9179e-256,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0945e-116,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9072e-131,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1192e-33, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.9757e-57]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.3790e-166]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4362e-175,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5653e-251,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.4072e-78]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.4194e-60]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.1291e-279]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 9.3193e-169]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5683e-88, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.3361e-131]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2920e-74, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1139e-229,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.6910e-32, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.1158e-171]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 7.7510e-205]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.4681e-214]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.1613e-112]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1733e-113,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.4644e-08]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.6792e-79]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1316, 0.8684]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5740e-118,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.9994e-01, 6.4794e-05]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3522e-82, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2919e-224,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 7.5207e-37]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5831e-236,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.0465e-234]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5263e-150,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4188e-110,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.4665e-104]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.2785e-294]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.6151e-100,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.1611e-42]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.8204e-41]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 7.4095e-32]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5295e-234,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.7356e-217]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4979e-312,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 8.1301e-132]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.3808e-57]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.0692e-107,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 8.0976e-291]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.2801e-35]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.7539e-79]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.1298e-307]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4129e-35, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0359, 0.9641]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.2340e-182]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 7.7794e-219]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6810e-167,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 5.4564e-298]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.8384e-221,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9966, 0.0034]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.0209e-60]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "epoch: i, loss: -1.0\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.9407e-324]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.5288e-103]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.6448e-305]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.3801e-57]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.0444e-236,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6481e-75, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.3188e-39]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7492e-267,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8170e-173,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.7032e-186,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.4354e-104,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.2475e-87, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1897e-282,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.5138e-272,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.0304e-226,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.6289e-285,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.0004e-129]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.4800e-258]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.0791e-278,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.1908e-309]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.3411e-20, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4581e-207,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.9076e-271]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 6.6042e-69]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.7910e-12]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.7710e-208]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.9768e-180,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.1432e-168]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.7250e-159]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.4717e-253]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4128e-107,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.6402e-223]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3154e-112,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.0038e-196,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.7722e-287]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.1168e-194]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.5421e-141,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.1043e-120]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9644e-229,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3696e-227,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8731e-239,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.2197e-274]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.5718e-312,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4466e-323,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 6.9854e-68]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4951e-129,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.0057e-21, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.4203e-317,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.3699e-315]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.2609e-83]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.0285e-72, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.6168e-08, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 4.2313e-80]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.8763e-127]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.7340e-314]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 5.1095e-296]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.0278e-74]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.4656e-287]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1723e-233,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.2465e-22]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.3444e-282]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3696e-245,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.5305e-56, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.0429e-318]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2277e-15, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8542e-160,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 9.2869e-97]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.6646e-208,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.2315e-199]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 8.4560e-58]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 6.7380e-79]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.7352e-252,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 7.1274e-276]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.4716e-130]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.1162e-115]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.8655e-26]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2230e-225,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.6445e-106]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.6047e-219,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7261e-125,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.0967e-69]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.1661e-176,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9836e-212,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9152e-132,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5958e-146,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "epoch: i, loss: 0.0\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1011e-109,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.3546e-210]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4930e-185,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6254e-129,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0022e-130,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8967e-112,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[9.1036e-257,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.4793e-105]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.1951e-213,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.1984e-120,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.0351e-115]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.4431e-216]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.1989e-277]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.2699e-246,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3116e-187,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8270e-269,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.5528e-116,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.5931e-59, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.5150e-35]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 6.6653e-276]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.2962e-295,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.3928e-293]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.6836e-18]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.9196e-302]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.4493e-266,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.5227e-245,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0627e-115,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.7889e-43]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4559e-286,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.3633e-235,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.5559e-239]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.5472e-09]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.6725e-12]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7993e-62, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0724e-117,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0757e-52, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 9.9479e-73]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2508e-45, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.8715e-88]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 5.3217e-81]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.3381e-126,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.8771e-288]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.9160e-101,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 8.3826e-76]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.1630e-55]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.2849e-51, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.7613e-112]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.4170e-115,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.3103e-242,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 9.9563e-142]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 7.3348e-261]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.2529, 0.7471]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.2679e-230,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[7.5743e-192,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7198e-63, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.7297e-320]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.0482e-102]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 5.0117e-284]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.0341e-242]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.6259e-68]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.7843e-161]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9766e-24, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.3020e-312,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.1508e-305]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.1747e-46, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.9618e-128,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 6.9968e-44]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.4563e-06]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0435e-210,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.7742e-170,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.6061e-48]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.0139e-84]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8.8581e-106,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 3.0883e-201]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8507e-294,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.1683e-99]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[5.4529e-99, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.4792e-273,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 9.3312e-123]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.1233e-11, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.8107e-76, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.2825e-89, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.1427e-79]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 2.8982e-185]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 1.8865e-193]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[3.0841e-160,  1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 1.0000e+00, 4.4835e-272]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.9631e-56, 1.0000e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 1.6541e-23]], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0., 1.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1., 0.]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59371/1708602542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_59371/1214785951.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, optimizer, train_loader, device, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: i, loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model(model, optim, data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.2",
   "language": "python",
   "name": "python-3.9.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
