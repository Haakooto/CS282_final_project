{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from models import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import training_utils as utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_data = utils.get_nanotube_data()\n",
    "X_test, Y_test = test_data\n",
    "lr_start = 0.00001\n",
    "fc_model = F3FC(7, 30, 20, 1).to(device)\n",
    "optimizer = Adam(fc_model.parameters(), lr=lr_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train_model(fc_model, optimizer, train_loader, device, 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "def plot_model_pred(model, Y_test, X_test):\n",
    "    Y_sample = Y_test.detach().numpy()[:100]\n",
    "    Y_pred_sample, kl = model(X_test)\n",
    "    Y_pred_sample = Y_pred_sample.detach().numpy()[:100]\n",
    "    plt.plot(Y_sample, \"bo-\", ms=8, label=\"target\")\n",
    "    plt.plot(Y_pred_sample, \"ro--\", ms=4, label=\"prediction\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_model_pred(fc_model, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_data = utils.get_nanotube_data(batch_size=10)\n",
    "lr_start = 0.001\n",
    "optimizer = Adam(fc_model.parameters(), lr=lr_start)\n",
    "\n",
    "def run_model(model, optimizer, train_loader, device, loss, num_epochs=30):\n",
    "    num_epochs = num_epochs\n",
    "    if loss == 'mse':\n",
    "        Loss_FN = torch.nn.MSELoss()\n",
    "    elif loss == 'nll':\n",
    "        Loss_FN = torch.nn.NLLLoss()\n",
    "    else:\n",
    "        print('Not Recgonized Loss Type')\n",
    "        return\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    sd = torch.std(train_loader.dataset.y)\n",
    "    for i in pbar:\n",
    "        for bi, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out, kl = model(x)\n",
    "            dist = torch.distributions.normal.Normal(loc=out, scale=sd)\n",
    "            # print(dist)\n",
    "            # input(\">>>\")\n",
    "            loss = torch.sum(-dist.log_prob(y))\n",
    "\n",
    "            # loss = Loss_FN(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pbar.set_description(f\"{loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model = Bayesian3FC(7, 30, 20, 1).to(device)\n",
    "bayes1 = BayesianFC(7, 1, [20, 20, 20]).to(device)\n",
    "run_model(bayes1, optimizer, train_loader, device, 'nll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_pred(bayes_model, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Parameter(torch.FloatTensor(1, 20).normal_(mean=0, std=0.001))\n",
    "print(torch.FloatTensor(1, 20).normal_(mean=0, std=0.001))\n",
    "print(torch.nn.Parameter(torch.FloatTensor(1, 20).normal_(mean=0, std=0.001)))\n",
    "torch.FloatTensor(1, 20).normal_(mean=0, std=0.001).log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "# w_mu = torch.nn.Parameter(torch.FloatTensor(1, 20).normal_(mean=0, std=0.001))\n",
    "# w_p = torch.nn.Parameter(torch.FloatTensor(1, 20).normal_(mean=-2.5, std=0.001))\n",
    "\n",
    "# print(w_mu)\n",
    "# print(w_p)\n",
    "\n",
    "b_mu = torch.nn.Parameter(torch.zeros(20))\n",
    "            # proxy for variance\n",
    "b_p = torch.nn.Parameter(torch.zeros(20))\n",
    "print(b_mu)\n",
    "print(b_p)\n",
    "\n",
    "def reparameterize(mu, p):\n",
    "        sigma = torch.log(1 + torch.exp(p)) \n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + (eps * sigma)\n",
    "\n",
    "b = reparameterize(b_mu, b_p)\n",
    "print(b)\n",
    "\n",
    "# log_prior = dist.Normal(0, 1).log_prob(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VM = dist.VonMises(torch.tensor([0.0]), torch.tensor([0.00031]))\n",
    "VM.sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e8d3d4799f327da20dd18e7e7a5bd6c8a402c99124f53a7c81166451855a22d"
  },
  "kernelspec": {
   "display_name": "3.9.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
